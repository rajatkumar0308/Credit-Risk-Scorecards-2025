{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "290f9f21-deb3-431b-89b8-41a70b097dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: Model Validation\n",
    "# ------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# --- Load Data ---\n",
    "file_path = r\"C:\\Users\\rajat\\OneDrive\\Desktop\\Inputs scorecard\\Customer_Final_Scores_with_Calibration.xlsx\"\n",
    "df_raw = pd.read_excel(file_path, sheet_name=\"RawData\")\n",
    "df_decile = pd.read_excel(file_path, sheet_name=\"DecileCalibration\")\n",
    "\n",
    "# Target and Score\n",
    "y_true = df_raw[\"Default_y\"]\n",
    "# Flip the score so higher score = better customer\n",
    "y_score = -df_raw[\"Final_Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57567a2a-1531-46c3-b12c-d70379344f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.761\n",
      "Accuracy Ratio (AR): 0.380\n"
     ]
    }
   ],
   "source": [
    "# 1. Gini & AR\n",
    "# ------------------------------------------------\n",
    "auc = roc_auc_score(y_true, y_score)\n",
    "gini = 2 * auc - 1\n",
    "ar = gini / 2\n",
    "\n",
    "print(f\"Gini: {gini:.3f}\")\n",
    "print(f\"Accuracy Ratio (AR): {ar:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eba858d-06ef-4677-a97b-836c726c9554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Statistic: 0.686\n"
     ]
    }
   ],
   "source": [
    "# 2. KS Statistic\n",
    "# ------------------------------------------------\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "ks_stat = max(tpr - fpr)\n",
    "print(f\"KS Statistic: {ks_stat:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9783929b-7ea8-4727-b9f3-f120bf91da0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank Order Table:\n",
      "   score_decile_10  total  bads  goods  bad_rate   avg_score\n",
      "0                0     10     1      9  0.100000  960.900000\n",
      "1                1     10     0     10  0.000000  880.300000\n",
      "2                2     10     0     10  0.000000  843.500000\n",
      "3                3     10     1      9  0.100000  801.900000\n",
      "4                4     10     2      8  0.200000  749.900000\n",
      "5                5     10     1      9  0.100000  694.700000\n",
      "6                6     11     4      7  0.363636  608.454545\n",
      "7                7      9     5      4  0.555556  515.222222\n",
      "8                8     10     8      2  0.800000  410.900000\n",
      "9                9     10     8      2  0.800000  219.300000\n"
     ]
    }
   ],
   "source": [
    "# 3. Rank Order\n",
    "# ------------------------------------------------\n",
    "df_raw[\"score_decile_10\"] = pd.qcut(y_score, 10, labels=False, duplicates=\"drop\")\n",
    "\n",
    "rank_order = df_raw.groupby(\"score_decile_10\").agg(\n",
    "    total=(\"Default_y\", \"count\"),\n",
    "    bads=(\"Default_y\", \"sum\"),\n",
    "    goods=(\"Default_y\", lambda x: (x == 0).sum()),\n",
    "    bad_rate=(\"Default_y\", \"mean\"),\n",
    "    avg_score=(\"Final_Score\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nRank Order Table:\")\n",
    "print(rank_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e28e2c0-cdd3-494c-af65-b6c2e53988cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PSI: 10.054\n"
     ]
    }
   ],
   "source": [
    "# 4. PSI (Population Stability Index)\n",
    "# ------------------------------------------------\n",
    "def calculate_psi(expected, actual, buckets=10):\n",
    "    breakpoints = np.arange(0, buckets + 1) / buckets * 100\n",
    "    breakpoints = np.percentile(expected, breakpoints)\n",
    "\n",
    "    expected_percents = np.histogram(expected, breakpoints)[0] / len(expected)\n",
    "    actual_percents = np.histogram(actual, breakpoints)[0] / len(actual)\n",
    "\n",
    "    psi_value = np.sum((actual_percents - expected_percents) *\n",
    "                       np.log((actual_percents + 1e-6) / (expected_percents + 1e-6)))\n",
    "    return psi_value\n",
    "\n",
    "psi_val = calculate_psi(df_raw[\"Final_Score\"], df_decile[\"calibrated_score\"])\n",
    "print(f\"\\nPSI: {psi_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7873a4b0-18e4-4460-948f-a93279fa9b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Concentration (Top 20% customers): 20.00%\n"
     ]
    }
   ],
   "source": [
    "# 5. Score Concentration\n",
    "# ------------------------------------------------\n",
    "score_threshold = np.percentile(df_raw[\"Final_Score\"], 80)\n",
    "concentration = (df_raw[\"Final_Score\"] >= score_threshold).mean()\n",
    "print(f\"Score Concentration (Top 20% customers): {concentration:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a399a1-8273-4b88-9ae3-6468c029d42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concordance / Discordance:\n",
      "{'concordant_pct': 0.11952380952380952, 'discordant_pct': 0.8804761904761905, 'ties_pct': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# 6. Concordance / Discordance\n",
    "# ------------------------------------------------\n",
    "def concordance_discordance(y_true, y_score):\n",
    "    good_scores = y_score[y_true == 0]\n",
    "    bad_scores = y_score[y_true == 1]\n",
    "    total_pairs = len(good_scores) * len(bad_scores)\n",
    "\n",
    "    concordant = discordant = ties = 0\n",
    "    for g in good_scores:\n",
    "        concordant += np.sum(g > bad_scores)\n",
    "        discordant += np.sum(g < bad_scores)\n",
    "        ties += np.sum(g == bad_scores)\n",
    "\n",
    "    return {\n",
    "        \"concordant_pct\": concordant / total_pairs,\n",
    "        \"discordant_pct\": discordant / total_pairs,\n",
    "        \"ties_pct\": ties / total_pairs,\n",
    "    }\n",
    "\n",
    "conc_disc = concordance_discordance(y_true.values, y_score.values)\n",
    "print(\"\\nConcordance / Discordance:\")\n",
    "print(conc_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169057cb-ef8f-4771-afe1-746c5cf320cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
