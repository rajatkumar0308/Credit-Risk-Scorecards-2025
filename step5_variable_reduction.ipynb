{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16ce3733-5163-46a3-a717-d9d09d723f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# -----------------------\n",
    "# Step 0: Load dataset\n",
    "# -----------------------\n",
    "file_path = r\"C:\\Users\\rajat\\OneDrive\\Desktop\\Inputs scorecard\\EDA_final_dataset.xlsx\"\n",
    "final_df = pd.read_excel(file_path, sheet_name=\"Sheet1\")\n",
    "\n",
    "# Set target column\n",
    "target = \"Default_y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47fc3375-ba60-48c4-916e-3c99c07015b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 Done ✅ → Variables after regulatory exclusion: 29\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Step 1: Regulatory Exclusions (if any)\n",
    "# -----------------------\n",
    "# Example: drop ID columns or leakage variables\n",
    "exclude_vars = [\"Customer_ID\"] if \"Customer_ID\" in final_df.columns else []\n",
    "final_df = final_df.drop(columns=exclude_vars, errors=\"ignore\")\n",
    "\n",
    "print(\"Step 1 Done ✅ → Variables after regulatory exclusion:\", final_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a236669-f968-4876-8af5-f39a5e7d9c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2 Done ✅ → IV Calculation\n",
      "                                Variable        IV              Strength\n",
      "2                             Income_INR  3.850526  Suspicious / Overfit\n",
      "20                     Outstanding_Loans  3.501148  Suspicious / Overfit\n",
      "10                    No_of_Inquiries_6M  3.491895  Suspicious / Overfit\n",
      "1                Behavior_Spending_Score  3.453279  Suspicious / Overfit\n",
      "4                     Loan_Tenure_Months  3.407736  Suspicious / Overfit\n",
      "15              Checking_Account_Balance  3.369120  Suspicious / Overfit\n",
      "19                           Loan_Amount  3.283799  Suspicious / Overfit\n",
      "6               Credit_Utilization_Ratio  3.206567  Suspicious / Overfit\n",
      "13                 No_of_Closed_Accounts  0.589163  Suspicious / Overfit\n",
      "0                        Education_Level  0.589163  Suspicious / Overfit\n",
      "9               Behavior_Repayment_Score  0.558637  Suspicious / Overfit\n",
      "25                                DPD_30  0.511931  Suspicious / Overfit\n",
      "11                 Credit_History_Length  0.511931  Suspicious / Overfit\n",
      "5   Months_Since_Most_Recent_Delinquency  0.511931  Suspicious / Overfit\n",
      "12                  Worst_Current_Status  0.503841  Suspicious / Overfit\n",
      "8                       Employment_Years  0.387994                Strong\n",
      "7                Credit_Card_Utilization  0.387994                Strong\n",
      "17                   No_of_Inquiries_12M  0.387994                Strong\n",
      "3                     Total_Credit_Limit  0.387994                Strong\n",
      "21              Oldest_Trade_Open_Months  0.387994                Strong\n",
      "18                       Delinquency_12M  0.349378                Strong\n",
      "22                 Total_Current_Balance  0.310762                Strong\n",
      "24                   No_of_Open_Accounts  0.310762                Strong\n",
      "14              Newest_Trade_Open_Months  0.225440                Medium\n",
      "27                               Cluster  0.225440                Medium\n",
      "26               Savings_Account_Balance  0.186825                Medium\n",
      "16                           Pay_History  0.178734                Medium\n",
      "23                   Max_Credit_Exposure  0.093412                  Weak\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# Step 2: IV Calculation with Classification\n",
    "# ------------------------------\n",
    "\n",
    "def calculate_iv(df, feature, target, bins=10):\n",
    "    \"\"\"\n",
    "    Calculate Information Value (IV) for a single feature.\n",
    "    \"\"\"\n",
    "    # Create bins\n",
    "    df[\"bin\"] = pd.qcut(df[feature].rank(method=\"first\"), bins, duplicates=\"drop\")\n",
    "\n",
    "    # Group by bin (observed=False fixes warning)\n",
    "    grouped = df.groupby(\"bin\", observed=False)[target].agg([\"count\", \"sum\"])\n",
    "    grouped[\"non_event\"] = grouped[\"count\"] - grouped[\"sum\"]\n",
    "\n",
    "    # Distributions\n",
    "    dist_event = grouped[\"sum\"] / grouped[\"sum\"].sum()\n",
    "    dist_non_event = grouped[\"non_event\"] / grouped[\"non_event\"].sum()\n",
    "\n",
    "    # IV calculation\n",
    "    iv = ((dist_event - dist_non_event) * \n",
    "          np.log((dist_event + 1e-10) / (dist_non_event + 1e-10))).sum()\n",
    "\n",
    "    return iv\n",
    "\n",
    "def classify_iv(iv):\n",
    "    \"\"\"\n",
    "    Classify variable predictive power based on IV value.\n",
    "    \"\"\"\n",
    "    if iv < 0.02:\n",
    "        return \"Not Useful\"\n",
    "    elif iv < 0.1:\n",
    "        return \"Weak\"\n",
    "    elif iv < 0.3:\n",
    "        return \"Medium\"\n",
    "    elif iv < 0.5:\n",
    "        return \"Strong\"\n",
    "    else:\n",
    "        return \"Suspicious / Overfit\"\n",
    "\n",
    "# ------------------------------\n",
    "# Apply to final_df\n",
    "# ------------------------------\n",
    "\n",
    "target = \"Default_y\"\n",
    "features = [col for col in final_df.columns if col != target]\n",
    "\n",
    "iv_results = {}\n",
    "\n",
    "for feature in features:\n",
    "    try:\n",
    "        iv_results[feature] = calculate_iv(final_df, feature, target, bins=10)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping {feature} due to error: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "iv_df = pd.DataFrame(list(iv_results.items()), columns=[\"Variable\", \"IV\"])\n",
    "iv_df[\"Strength\"] = iv_df[\"IV\"].apply(classify_iv)\n",
    "\n",
    "print(\"\\nStep 2 Done ✅ → IV Calculation\")\n",
    "print(iv_df.sort_values(by=\"IV\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c36a073-49e8-4e3f-8004-e9da606e0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3 Done ✅ → Variables with relaxed monotonic WOE:\n",
      "['Loan_Tenure_Months', 'Months_Since_Most_Recent_Delinquency', 'Credit_Utilization_Ratio', 'Credit_Card_Utilization', 'No_of_Inquiries_6M', 'Newest_Trade_Open_Months', 'Checking_Account_Balance', 'Delinquency_12M', 'Total_Current_Balance', 'No_of_Open_Accounts', 'Savings_Account_Balance']\n",
      "Dataset shape after Step 3: (100, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# Step 3: WOE Monotonic Trend Check \n",
    "# ------------------------------\n",
    "\n",
    "def check_almost_monotonic_woe(df, feature, target, bins=5, tolerance=2):\n",
    "    \"\"\"\n",
    "    Check if WOE values for a feature are *almost monotonic*.\n",
    "    Allows up to `tolerance` direction changes.\n",
    "    Uses fewer bins to smooth noise.\n",
    "    \"\"\"\n",
    "    df[\"bin\"] = pd.qcut(df[feature].rank(method=\"first\"), bins, duplicates=\"drop\")\n",
    "\n",
    "    grouped = df.groupby(\"bin\", observed=False)[target].agg([\"count\", \"sum\"])\n",
    "    grouped[\"non_event\"] = grouped[\"count\"] - grouped[\"sum\"]\n",
    "\n",
    "    dist_event = grouped[\"sum\"] / grouped[\"sum\"].sum()\n",
    "    dist_non_event = grouped[\"non_event\"] / grouped[\"non_event\"].sum()\n",
    "\n",
    "    woe_values = np.log((dist_event + 1e-10) / (dist_non_event + 1e-10)).values\n",
    "\n",
    "    # Find direction changes\n",
    "    diffs = np.sign(np.diff(woe_values))\n",
    "    changes = np.sum(diffs[1:] != diffs[:-1])\n",
    "\n",
    "    return changes <= tolerance   # Allow up to N changes\n",
    "\n",
    "# ------------------------------\n",
    "# Apply to final_df\n",
    "# ------------------------------\n",
    "\n",
    "target = \"Default_y\"\n",
    "features = [col for col in final_df.columns if col != target]\n",
    "\n",
    "monotonic_vars = []\n",
    "\n",
    "for feature in features:\n",
    "    try:\n",
    "        if check_almost_monotonic_woe(final_df, feature, target, bins=5, tolerance=2):\n",
    "            monotonic_vars.append(feature)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping {feature} due to error: {e}\")\n",
    "\n",
    "# Keep only selected variables + target\n",
    "final_df_step3 = final_df[monotonic_vars + [target]]\n",
    "\n",
    "print(\"\\nStep 3 Done ✅ → Variables with relaxed monotonic WOE:\")\n",
    "print(monotonic_vars)\n",
    "print(f\"Dataset shape after Step 3: {final_df_step3.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1320285-9eb3-4aa3-8bdc-b9c889504ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4 Done ✅ → VIF values\n",
      "                                Variable       VIF\n",
      "1                Behavior_Spending_Score  1.597960\n",
      "2                             Income_INR  1.584497\n",
      "3                     Total_Credit_Limit  1.275800\n",
      "4                     Loan_Tenure_Months  1.538533\n",
      "5   Months_Since_Most_Recent_Delinquency  1.551407\n",
      "6               Credit_Utilization_Ratio  1.537819\n",
      "7                Credit_Card_Utilization  1.490912\n",
      "8                       Employment_Years  1.522870\n",
      "9               Behavior_Repayment_Score  1.446245\n",
      "10                    No_of_Inquiries_6M  1.701075\n",
      "11                 Credit_History_Length  1.394881\n",
      "12                  Worst_Current_Status  1.459092\n",
      "13                 No_of_Closed_Accounts  1.446409\n",
      "14              Newest_Trade_Open_Months  1.560629\n",
      "15              Checking_Account_Balance  1.506160\n",
      "16                   No_of_Inquiries_12M  1.404393\n",
      "17                       Delinquency_12M  1.538489\n",
      "18                           Loan_Amount  1.471337\n",
      "19                     Outstanding_Loans  1.998206\n",
      "20              Oldest_Trade_Open_Months  1.432470\n",
      "21                 Total_Current_Balance  1.462638\n",
      "22                   Max_Credit_Exposure  1.406732\n",
      "23                   No_of_Open_Accounts  1.233203\n",
      "24                                DPD_30  1.362646\n",
      "25               Savings_Account_Balance  1.274791\n",
      "26                               Cluster  3.944875\n",
      "Variables kept after VIF filtering: ['Behavior_Spending_Score', 'Income_INR', 'Total_Credit_Limit', 'Loan_Tenure_Months', 'Months_Since_Most_Recent_Delinquency', 'Credit_Utilization_Ratio', 'Credit_Card_Utilization', 'Employment_Years', 'Behavior_Repayment_Score', 'No_of_Inquiries_6M', 'Credit_History_Length', 'Worst_Current_Status', 'No_of_Closed_Accounts', 'Newest_Trade_Open_Months', 'Checking_Account_Balance', 'No_of_Inquiries_12M', 'Delinquency_12M', 'Loan_Amount', 'Outstanding_Loans', 'Oldest_Trade_Open_Months', 'Total_Current_Balance', 'Max_Credit_Exposure', 'No_of_Open_Accounts', 'DPD_30', 'Savings_Account_Balance', 'Cluster']\n",
      "\n",
      "✅ Final dataset shape: (100, 27)\n",
      "✅ Final variables used: ['Behavior_Spending_Score', 'Income_INR', 'Total_Credit_Limit', 'Loan_Tenure_Months', 'Months_Since_Most_Recent_Delinquency', 'Credit_Utilization_Ratio', 'Credit_Card_Utilization', 'Employment_Years', 'Behavior_Repayment_Score', 'No_of_Inquiries_6M', 'Credit_History_Length', 'Worst_Current_Status', 'No_of_Closed_Accounts', 'Newest_Trade_Open_Months', 'Checking_Account_Balance', 'No_of_Inquiries_12M', 'Delinquency_12M', 'Loan_Amount', 'Outstanding_Loans', 'Oldest_Trade_Open_Months', 'Total_Current_Balance', 'Max_Credit_Exposure', 'No_of_Open_Accounts', 'DPD_30', 'Savings_Account_Balance', 'Cluster', 'Default_y']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Step 4: Multicollinearity (VIF)\n",
    "# -----------------------\n",
    "X = final_df.drop(columns=[target])\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "if not X.empty:\n",
    "    X_const = add_constant(X)\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"Variable\"] = X_const.columns\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]\n",
    "    vif_df = vif_df[vif_df[\"Variable\"] != \"const\"]\n",
    "\n",
    "    # Keep variables with VIF < 5\n",
    "    final_vars = vif_df.loc[vif_df[\"VIF\"] < 5, \"Variable\"].tolist()\n",
    "    final_df = final_df[final_vars + [target]]\n",
    "\n",
    "    print(\"\\nStep 4 Done ✅ → VIF values\")\n",
    "    print(vif_df)\n",
    "    print(\"Variables kept after VIF filtering:\", final_vars)\n",
    "else:\n",
    "    print(\"\\nNo numeric variables left for VIF check.\")\n",
    "\n",
    "# -----------------------\n",
    "# Final Output\n",
    "# -----------------------\n",
    "print(\"\\n✅ Final dataset shape:\", final_df.shape)\n",
    "print(\"✅ Final variables used:\", final_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec33b7f4-316e-4551-8abd-59df91afd074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final dataset saved to: C:\\Users\\rajat\\OneDrive\\Desktop\\Inputs scorecard\\Final_Model_Dataset.xlsx\n",
      "Shape: (100, 27)\n",
      "Columns: ['Behavior_Spending_Score', 'Income_INR', 'Total_Credit_Limit', 'Loan_Tenure_Months', 'Months_Since_Most_Recent_Delinquency', 'Credit_Utilization_Ratio', 'Credit_Card_Utilization', 'Employment_Years', 'Behavior_Repayment_Score', 'No_of_Inquiries_6M', 'Credit_History_Length', 'Worst_Current_Status', 'No_of_Closed_Accounts', 'Newest_Trade_Open_Months', 'Checking_Account_Balance', 'No_of_Inquiries_12M', 'Delinquency_12M', 'Loan_Amount', 'Outstanding_Loans', 'Oldest_Trade_Open_Months', 'Total_Current_Balance', 'Max_Credit_Exposure', 'No_of_Open_Accounts', 'DPD_30', 'Savings_Account_Balance', 'Cluster', 'Default_y']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Save Final Dataset\n",
    "# -----------------------\n",
    "\n",
    "output_path = r\"C:\\Users\\rajat\\OneDrive\\Desktop\\Inputs scorecard\\Final_Model_Dataset.xlsx\"\n",
    "\n",
    "# Save final_df into Excel\n",
    "final_df.to_excel(output_path, sheet_name=\"Model_Data\", index=False)\n",
    "\n",
    "print(f\"✅ Final dataset saved to: {output_path}\")\n",
    "print(\"Shape:\", final_df.shape)\n",
    "print(\"Columns:\", final_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f0381-5df4-469d-a9b8-709b543bbfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
